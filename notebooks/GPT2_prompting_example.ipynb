{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: The purpose of artificial intelligence is\n",
      "Generated: The purpose of artificial intelligence is to make life more pleasurable. We can't stop people from trying, but we don\n",
      "\"t want the human body being harmed by a technology that gives us pleasure,\" says Kalyan Kumar Chaudhary (author of Artificial Intelligence: How The Mind Can Help Us Make It Better). \"I think what makes AI interesting in this regard is how it brings together different types and approaches into one.\" As an example for me, I've been told there are\n",
      "--------------------------------------------------\n",
      "Prompt: The solution to climate change requires\n",
      "Generated: The solution to climate change requires a fundamental shift in our focus, including the emergence of new technologies that are not simply economic but also social and ecological. We need these solutions because we know they will lead us toward an unprecedented period when human beings can no longer depend on their environment for energy production.\"\n",
      "/iStockphoto/Getty Images\n",
      "--------------------------------------------------\n",
      "Prompt: In mathematics, the concept of infinity\n",
      "Generated: In mathematics, the concept of infinity is used in various ways. For example: 1 + 2 = 3 * 4; (3+2)*4=5*6 - 6\n",
      "For an infinite number and its corresponding functions such as a positive integer or vector it can be defined by taking two distinct types — A : 0x1e^-0f → ∞A . We will use this to define all possible possibilities for finite numbers if we wish to understand how things work around those problems\n",
      "--------------------------------------------------\n",
      "Prompt: The future of neural networks will\n",
      "Generated: The future of neural networks will be defined by the development and use in machine learning, as well. This is where we look at a new feature from Deep Learning: non-linear reinforcement (NN).\n",
      "In our paper to this effect, NNAs have been studied for many years on both deep network training programs that target large volumes or larger sets using distributed sparse models such with very little effort due to their low cost because they are always connected across multiple tasks during an action cycle while not being interrupted\n",
      "--------------------------------------------------\n",
      "Prompt: For effective mathematical reasoning, language models need to\n",
      "Generated: For effective mathematical reasoning, language models need to be able see what happens if we can't express the meanings of words and symbols. And these are just three examples; as well:\n",
      "1) The semantics behind this problem is much simpler than you might think (e...g). For example … \"fag\" = cat . Let's say I wanted to put a dog on your computer by saying that it was not feline but rather an animal which actually had fur inside its ears… This would\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"gpt2\"  # Can be \"gpt2\", \"gpt2-medium\", \"gpt2-large\", or \"gpt2-xl\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set the padding token to be the EOS token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = TFGPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "def generate_text(prompt, max_length=100):\n",
    "    \"\"\"\n",
    "    Generate text based on a prompt using GPT-2\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The input text to continue from\n",
    "        max_length (int): Maximum length of generated text (including prompt)\n",
    "        \n",
    "    Returns:\n",
    "        str: Generated text\n",
    "    \"\"\"\n",
    "    # Encode the prompt with proper padding and attention mask\n",
    "    encoded_input = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors='tf',\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length\n",
    "    )\n",
    "    \n",
    "    # Extract the input_ids and attention_mask\n",
    "    input_ids = encoded_input['input_ids']\n",
    "    attention_mask = encoded_input['attention_mask']\n",
    "    \n",
    "    # Generate text with attention mask\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=max_length,\n",
    "        temperature=0.8,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=tokenizer.eos_token_id,  # Explicitly set pad_token_id\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    \n",
    "    # Decode the generated text\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Example prompts to try\n",
    "prompts = [\n",
    "    \"The purpose of artificial intelligence is\",\n",
    "    \"The solution to climate change requires\",\n",
    "    \"In mathematics, the concept of infinity\",\n",
    "    \"The future of neural networks will\",\n",
    "    \"For effective mathematical reasoning, language models need to\"\n",
    "]\n",
    "\n",
    "# Try different prompts\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    generated = generate_text(prompt)\n",
    "    print(f\"Generated: {generated}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
